[program started on Thu Oct 29 13:46:15 2015] 
[command line arguments] 
nInputFeature 1 
net_init_seed 1 
inputSize 2500 
rundir experiment 
feature_extract_type max 
mwindow 50 
batchsize 30 
trdata_type chal600+mimicAll 
lr_sup 0.001 
lrdecay 1e-05 
nTarget 2 
db_seed 1 
max_upIter 42000 
momentum 0 
dropout_rate 0.5 
mlp_architecture table: 0x40ddbd88 
mlp_string [500-500] 
testdata_type chal+mimic 
[----------------------] 
==> Load datasets 

 6220
 2500
[torch.LongStorage of size 2]
 

  256
 2500
[torch.LongStorage of size 2]
 
==> Construct Neural Nets model 
2451 
nn.Sequential {
  [input -> (1) -> (2) -> (3) -> (4) -> (5) -> (6) -> (7) -> (8) -> (9) -> output]
  (1): nn.Reshape(2451)
  (2): nn.Linear(2451 -> 500)
  (3): nn.ReLU
  (4): nn.Dropout(0.500000)
  (5): nn.Linear(500 -> 500)
  (6): nn.ReLU
  (7): nn.Dropout(0.500000)
  (8): nn.Linear(500 -> 2)
  (9): nn.LogSoftMax
} 
==> Defining loss 
==> Defining some tools 
==> configuring optimizer 
==> Defining training procedure 
==> Start training 
==> # of max iteration: 202 

==> doing epoch on training data: 
==> online epoch # 1 [batchSize = 30] 
==> time to learn 1 sample = 3.3367022440748ms 
==> current training error = 0.69151440088468 

==> doing epoch on training data: 
==> online epoch # 2 [batchSize = 30] 
